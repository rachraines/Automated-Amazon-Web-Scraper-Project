# Automated-Amazon-Web-Scraper-Project
Python project demonstrating web data collection, cleaning, and exploratory analysis using requests, BeautifulSoup, and pandas.


## Project Overview
This project demonstrates how to collect data from the web and prepare it for analysis using Python. The workflow includes sending HTTP requests, parsing HTML content, cleaning raw data, and organizing it into a structured format suitable for exploratory data analysis.

The goal of this project is to showcase core data analyst skills such as data acquisition, data cleaning, and basic analysis using real-world tools and workflows.

---

## Tools & Technologies
- **Python**
- **requests** – sending HTTP requests
- **BeautifulSoup** – parsing HTML content
- **pandas** – data cleaning and transformation
- **Jupyter Notebook**

---

## Key Steps
1. **Web Data Collection**
   - Sent HTTP requests to retrieve webpage content
   - Parsed HTML elements to extract relevant data fields

2. **Data Cleaning & Preparation**
   - Converted raw scraped data into structured tabular format
   - Handled missing values and formatting inconsistencies
   - Renamed and organized columns for clarity

3. **Exploratory Data Analysis (EDA)**
   - Inspected distributions and summary statistics
   - Validated data quality and structure
   - Prepared clean datasets for downstream analysis or visualization

---

## Project Outcome
- Successfully transformed unstructured web data into a clean, analysis-ready dataset
- Demonstrated an end-to-end data workflow from data collection to analysis
- Produced a reusable scraping and cleaning pipeline using Python
